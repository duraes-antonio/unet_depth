{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "depth_estimation.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Depth Estimation (POC)\n",
    "\n",
    "[Based on](https://github.com/siddinc/monocular_depth_estimation/blob/master/notebooks/depth_estimation.ipynb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y1lMBdR4bCjf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "87607f99-42c6-48ef-bfbc-ad0f8a437632",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "\n",
    "print('Found GPU at: {}'.format(device_name))"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zR1W_MNWFWO2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from tensorflow.keras.layers import Input, concatenate, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import imutils"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8WCE7uaWLfQV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "HEIGHT = 480\n",
    "WIDTH = 640\n",
    "INIT_LR = 0.0001\n",
    "EPOCHS = 15\n",
    "TRAIN_PATH = \"./data/nyu2_train.csv\"\n",
    "TEST_PATH = \"./data/nyu2_test.csv\""
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-N0dzZdeUZe4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def downsampling_block(input_tensor, n_filters):\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same')(input_tensor)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def upsampling_block(input_tensor, n_filters, name, concat_with):\n",
    "    x = UpSampling2D((2, 2), interpolation='bilinear', name=name)(input_tensor)\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name + \"_convA\")(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = concatenate([x, concat_with], axis=3)\n",
    "\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name + \"_convB\")(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name + \"_convC\")(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VsDD_ZHBTOPO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def build(height, width, depth):\n",
    "    # input\n",
    "    i = Input(shape=(height, width, depth))\n",
    "\n",
    "    # encoder\n",
    "    conv1 = downsampling_block(i, 32)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = downsampling_block(pool1, 64)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = downsampling_block(pool2, 128)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = downsampling_block(pool3, 256)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    # bottleneck\n",
    "    conv5 = Conv2D(512, (3, 3), padding='same')(pool4)\n",
    "    conv5 = LeakyReLU(alpha=0.2)(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), padding='same')(conv5)\n",
    "    conv5 = LeakyReLU(alpha=0.2)(conv5)\n",
    "\n",
    "    # decoder\n",
    "    conv6 = upsampling_block(conv5, 256, \"up1\", concat_with=conv4)\n",
    "    conv7 = upsampling_block(conv6, 128, \"up2\", concat_with=conv3)\n",
    "    conv8 = upsampling_block(conv7, 64, \"up3\", concat_with=conv2)\n",
    "    conv9 = upsampling_block(conv8, 32, \"up4\", concat_with=conv1)\n",
    "\n",
    "    # output\n",
    "    o = Conv2D(filters=1, kernel_size=3, strides=(1, 1), activation='sigmoid', padding='same', name='conv10')(conv9)\n",
    "\n",
    "    model = Model(inputs=i, outputs=o)\n",
    "    return model"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V5ZqWmFD-JE9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "model = build(HEIGHT, WIDTH, 3)"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kVoO5XvZJHQC",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "71ac76c7-cbe7-4571-ca67-4f62736a4f88",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "model.summary()\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# plot_model(model, to_file='./model.png')"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 480, 640, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 480, 640, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 480, 640, 32  0           ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 480, 640, 32  128        ['leaky_re_lu[0][0]']            \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 480, 640, 32  9248        ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 480, 640, 32  0           ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 480, 640, 32  128        ['leaky_re_lu_1[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 240, 320, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 240, 320, 64  18496       ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 240, 320, 64  0           ['conv2d_2[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 240, 320, 64  256        ['leaky_re_lu_2[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 240, 320, 64  36928       ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 240, 320, 64  0           ['conv2d_3[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 240, 320, 64  256        ['leaky_re_lu_3[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 120, 160, 64  0          ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 120, 160, 12  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 120, 160, 12  0           ['conv2d_4[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 120, 160, 12  512        ['leaky_re_lu_4[0][0]']          \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 120, 160, 12  147584      ['batch_normalization_4[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 120, 160, 12  0           ['conv2d_5[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 120, 160, 12  512        ['leaky_re_lu_5[0][0]']          \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 60, 80, 128)  0          ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 60, 80, 256)  295168      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 60, 80, 256)  0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 60, 80, 256)  1024       ['leaky_re_lu_6[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 60, 80, 256)  590080      ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 60, 80, 256)  0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 60, 80, 256)  1024       ['leaky_re_lu_7[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 30, 40, 256)  0          ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 30, 40, 512)  1180160     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 30, 40, 512)  0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 30, 40, 512)  2359808     ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 30, 40, 512)  0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " up1 (UpSampling2D)             (None, 60, 80, 512)  0           ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " up1_convA (Conv2D)             (None, 60, 80, 256)  1179904     ['up1[0][0]']                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 60, 80, 256)  0           ['up1_convA[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 60, 80, 512)  0           ['leaky_re_lu_10[0][0]',         \n",
      "                                                                  'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " up1_convB (Conv2D)             (None, 60, 80, 256)  1179904     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 60, 80, 256)  0           ['up1_convB[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 60, 80, 256)  1024       ['leaky_re_lu_11[0][0]']         \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " up1_convC (Conv2D)             (None, 60, 80, 256)  590080      ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 60, 80, 256)  0           ['up1_convC[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 60, 80, 256)  1024       ['leaky_re_lu_12[0][0]']         \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " up2 (UpSampling2D)             (None, 120, 160, 25  0           ['batch_normalization_9[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " up2_convA (Conv2D)             (None, 120, 160, 12  295040      ['up2[0][0]']                    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 120, 160, 12  0           ['up2_convA[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 120, 160, 25  0           ['leaky_re_lu_13[0][0]',         \n",
      "                                6)                                'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " up2_convB (Conv2D)             (None, 120, 160, 12  295040      ['concatenate_1[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 120, 160, 12  0           ['up2_convB[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 120, 160, 12  512        ['leaky_re_lu_14[0][0]']         \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " up2_convC (Conv2D)             (None, 120, 160, 12  147584      ['batch_normalization_10[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 120, 160, 12  0           ['up2_convC[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 120, 160, 12  512        ['leaky_re_lu_15[0][0]']         \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " up3 (UpSampling2D)             (None, 240, 320, 12  0           ['batch_normalization_11[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up3_convA (Conv2D)             (None, 240, 320, 64  73792       ['up3[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)     (None, 240, 320, 64  0           ['up3_convA[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 240, 320, 12  0           ['leaky_re_lu_16[0][0]',         \n",
      "                                8)                                'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " up3_convB (Conv2D)             (None, 240, 320, 64  73792       ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 240, 320, 64  0           ['up3_convB[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 240, 320, 64  256        ['leaky_re_lu_17[0][0]']         \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " up3_convC (Conv2D)             (None, 240, 320, 64  36928       ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)     (None, 240, 320, 64  0           ['up3_convC[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 240, 320, 64  256        ['leaky_re_lu_18[0][0]']         \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " up4 (UpSampling2D)             (None, 480, 640, 64  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up4_convA (Conv2D)             (None, 480, 640, 32  18464       ['up4[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)     (None, 480, 640, 32  0           ['up4_convA[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 480, 640, 64  0           ['leaky_re_lu_19[0][0]',         \n",
      "                                )                                 'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " up4_convB (Conv2D)             (None, 480, 640, 32  18464       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)     (None, 480, 640, 32  0           ['up4_convB[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 480, 640, 32  128        ['leaky_re_lu_20[0][0]']         \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " up4_convC (Conv2D)             (None, 480, 640, 32  9248        ['batch_normalization_14[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)     (None, 480, 640, 32  0           ['up4_convC[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 480, 640, 32  128        ['leaky_re_lu_21[0][0]']         \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv10 (Conv2D)                (None, 480, 640, 1)  289         ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,638,433\n",
      "Trainable params: 8,634,593\n",
      "Non-trainable params: 3,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E84h7_L3nVai",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "outputId": "3b4a5dd4-a39f-4948-9da5-00fe030e8a2a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# !git clone https: // gitlab.com / siddinc / new_depth.git./ data"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Sc3VZn6BpWB3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# loading the dataset\n",
    "\n",
    "def read_csv(csv_file_path):\n",
    "    with open(csv_file_path, 'r') as f:\n",
    "        csv_reader = csv.reader(f, delimiter=',')\n",
    "        return [('./' + row[0], './' + row[1]) for row in csv_reader if len(row) > 0]\n",
    "\n",
    "\n",
    "def train_val_split(train_paths, val_size):\n",
    "    random.shuffle(train_paths)\n",
    "    len_train_paths = len(train_paths)\n",
    "    i = int(len_train_paths * (1.0 - val_size))\n",
    "    train = train_paths[0:i]\n",
    "    val = train_paths[i:len(train_paths)]\n",
    "    return train, val\n",
    "\n",
    "\n",
    "def load_train_paths(train_path):\n",
    "    train_paths = read_csv(train_path)\n",
    "    labels = {img_path: dm_path for img_path, dm_path in train_paths}\n",
    "    x_paths = [img_path for img_path, dm in train_paths]\n",
    "    x_train_paths, x_val_paths = train_val_split(x_paths, 0.3)\n",
    "\n",
    "    partition = {\n",
    "        'train': x_train_paths,\n",
    "        'validation': x_val_paths\n",
    "    }\n",
    "    return partition, labels"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "v5A0zMBbIiTm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# preprocessing the dataset\n",
    "\n",
    "def normalize_img(img):\n",
    "    norm_img = (img - img.min()) / (img.max() - img.min())\n",
    "    return norm_img\n",
    "\n",
    "\n",
    "def preprocess_image(img_path, horizontal_flip=False):\n",
    "    image = cv2.imread(img_path)\n",
    "    image = imutils.resize(image, height=HEIGHT)\n",
    "    # image = image[:, 21:149].astype(\"float\")\n",
    "    image = image.astype(\"float\")\n",
    "    image = normalize_img(image)\n",
    "\n",
    "    if horizontal_flip:\n",
    "        image = cv2.flip(image, 1)\n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocess_depth_map(depth_map_path, horizontal_flip=False):\n",
    "    depth_map = cv2.imread(depth_map_path)\n",
    "    depth_map = cv2.cvtColor(depth_map, cv2.COLOR_BGR2GRAY)\n",
    "    depth_map = imutils.resize(depth_map, height=HEIGHT)\n",
    "    # depth_map = depth_map[:, 21:149].astype(\"float\")\n",
    "    depth_map = depth_map.astype(\"float\")\n",
    "    depth_map = normalize_img(depth_map)\n",
    "\n",
    "    if horizontal_flip:\n",
    "        depth_map = cv2.flip(depth_map, 1)\n",
    "\n",
    "    depth_map = np.reshape(depth_map, (depth_map.shape[0], depth_map.shape[1], 1))\n",
    "    return depth_map"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j9sF1JGWsHX8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# data generator\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, list_IDs, labels, batch_size=16, dim=(128, 128), n_channels=3, shuffle=True, pred=False):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.pred = pred\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        if self.pred:\n",
    "            X = self.__data_generation(list_IDs_temp)\n",
    "            return X\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        X = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels))\n",
    "\n",
    "        if not self.pred:\n",
    "            y = np.empty((self.batch_size, self.dim[0], self.dim[1], 1))\n",
    "\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                res = random.choice([True, False])\n",
    "                X[i,] = preprocess_image(ID, res)\n",
    "                y[i,] = preprocess_depth_map(self.labels[ID], res)\n",
    "            return X, y\n",
    "        else:\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                res = random.choice([True, False])\n",
    "                X[i,] = preprocess_image(ID, res)\n",
    "            return X"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QkBOJZ_Dpdlw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "partition, labels = load_train_paths(TRAIN_PATH)"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FT48gQIhs96D",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "67b81705-254b-4e1e-f52f-e724f010cbfd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(len(partition['train']), len(partition['validation']))"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22437 9617\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_m6BvnS2saux",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "BATCH_SIZE = 1\n",
    "training_generator = DataGenerator(\n",
    "    list_IDs=partition['train'], labels=labels, batch_size=BATCH_SIZE,\n",
    "    dim=(HEIGHT, WIDTH), n_channels=3, shuffle=True, pred=False\n",
    ")\n",
    "validation_generator = DataGenerator(\n",
    "    list_IDs=partition['validation'], labels=labels, batch_size=BATCH_SIZE,\n",
    "    dim=(HEIGHT, WIDTH), n_channels=3, shuffle=True, pred=False\n",
    ")"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G9OGPcceIkPt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def poly_decay(epoch):\n",
    "    maxEpochs = EPOCHS\n",
    "    baseLR = INIT_LR\n",
    "    power = 1.0\n",
    "    alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    "    return alpha\n",
    "\n",
    "\n",
    "opt = Adam(lr=INIT_LR, amsgrad=True)\n",
    "callbacks = [LearningRateScheduler(poly_decay)]\n",
    "\n",
    "\n",
    "# custom loss\n",
    "def depth_loss(y_true, y_pred):\n",
    "    w1, w2, w3 = 1.0, 1.0, 0.1\n",
    "\n",
    "    l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)\n",
    "\n",
    "    dy_true, dx_true = tf.image.image_gradients(y_true)\n",
    "    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
    "    l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\n",
    "\n",
    "    l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, 1.0)) * 0.5, 0, 1)\n",
    "\n",
    "    return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))\n",
    "\n",
    "\n",
    "#custom soft accuracy\n",
    "def depth_acc(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.round(y_true), K.round(y_pred)))"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [1], line 9\u001B[0m\n\u001B[0;32m      5\u001B[0m     alpha \u001B[38;5;241m=\u001B[39m baseLR \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m (epoch \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mfloat\u001B[39m(maxEpochs))) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m power\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m alpha\n\u001B[1;32m----> 9\u001B[0m opt \u001B[38;5;241m=\u001B[39m \u001B[43mAdam\u001B[49m(lr\u001B[38;5;241m=\u001B[39mINIT_LR, amsgrad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     10\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m [LearningRateScheduler(poly_decay)]\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# custom loss\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Adam' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WjSOVkB2tOm4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "model.compile(optimizer=opt, loss=depth_loss, metrics=[depth_acc])"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GqafvJUltZxE",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "outputId": "31bbf681-e160-4ed8-ed06-4020df9a451f",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [
    "r = model.fit(training_generator, validation_data=validation_generator, epochs=4, callbacks=callbacks)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gHW9K8GVSKSU",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "outputId": "3275d52d-1eeb-4d66-d908-9ff197857909",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "# e = np.linspace(1, EPOCHS, num=EPOCHS)\n",
    "\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "\n",
    "plt.plot(r.history['depth_acc'], label='acc')\n",
    "plt.plot(r.history['val_depth_acc'], label='val_acc')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Px5vYNC26Lrv",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "3acb9b6f-f9d1-4bb2-e5c3-ef8ef51013a3",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [
    "img_dm_pairs = read_csv('./data/nyu2_test.csv')\n",
    "labels = {i: j for i, j in img_dm_pairs}\n",
    "test_paths = [i for i, j in img_dm_pairs]\n",
    "print(len(test_paths))\n",
    "partition = {'test': test_paths}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kqyKOY7k8T2h",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [
    "x_test = np.empty((len(test_paths), HEIGHT, WIDTH, 3))\n",
    "y_test = np.empty((len(test_paths), HEIGHT, WIDTH, 1))\n",
    "\n",
    "for i, ID in enumerate(partition['test'][:]):\n",
    "    x_test[i,] = preprocess_image(ID, horizontal_flip=False)\n",
    "    y_test[i,] = preprocess_depth_map(labels[ID], horizontal_flip=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZGkuU7ue2K_3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "outputId": "44e5dc91-dea3-41b2-cf6e-9309047606e1",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [
    "print(model.evaluate(x_test, y_test))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1Ykd9KdP7Ppc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "c1cfffdb-ce6a-441b-e5b5-e27e228448c7",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "preds = model.predict(x_test)\n",
    "\n",
    "for i in range(len(test_paths) - 600):\n",
    "    path = partition['test'][i]\n",
    "    label_path = labels[path]\n",
    "    pred = preds[i]\n",
    "    pred = np.squeeze(pred, axis=-1)\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(pred, cmap=plt.get_cmap('inferno_r'))\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.axis(\"off\")\n",
    "    img = preprocess_depth_map(label_path, horizontal_flip=False)\n",
    "    img = np.squeeze(img, axis=-1)\n",
    "    plt.imshow(img, cmap=plt.get_cmap('inferno_r'))\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.axis(\"off\")\n",
    "    img1 = preprocess_image(path, horizontal_flip=False)\n",
    "    plt.imshow(img1)\n",
    "\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TsDkVaimiL3_",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ]
}