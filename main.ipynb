{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# U-Net Depth (Projeto de dissertação)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clonar e navegar para o repositório"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "running_remote = False\n",
    "running_on_kaggle = False\n",
    "db_name = 'unet_depth'\n",
    "repository_name = 'unet_depth'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clone e navegue para o repositório da dissertação\n",
    "if running_remote:\n",
    "    !git clone \"https://github.com/duraes-antonio/unet_depth\"\n",
    "    !cd $repository_name\n",
    "    os.chdir(repository_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if running_remote:\n",
    "    !git checkout poc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definir variáveis de ambiente e credenciais para serviços"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "if running_remote:\n",
    "    !pip install pymongo[srv] dnspython keras-unet-collection python-dotenv imutils\n",
    "    !pip install py-cpuinfo gpuinfo\n",
    "\n",
    "if running_on_kaggle:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "    user_secrets = UserSecretsClient()\n",
    "    database_url = user_secrets.get_secret(\"DATABASE_URL\")\n",
    "    google_cred_json = ast.literal_eval(user_secrets.get_secret(\"GOOGLE_CREDENTIALS_JSON\"))\n",
    "    google_token_json = ast.literal_eval(user_secrets.get_secret(\"GOOGLE_TOKEN_JSON\"))\n",
    "\n",
    "    with open('google_credentials.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(google_cred_json, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    with open('token.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(google_token_json, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    os.environ[\"DATABASE_URL\"] = database_url\n",
    "    os.environ[\"DB_NAME\"] = db_name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instanciar serviços para persistência de resultados e blob"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from infra.services.blob_storage.blob_storage_service_google_drive import GoogleDriveBlobStorageService\n",
    "from infra.services.model_storage_service_google_drive import ModelStorageServiceGoogleDrive\n",
    "from domain.services.model_storage_service import ModelStorageService\n",
    "from infra.services.test_case_execution_service_mongodb import TestCaseExecutionServiceMongoDB\n",
    "from infra.services.test_case_service_mongodb import TestCaseServiceMongoDB\n",
    "from domain.services.test_case_execution_service import TestCaseExecutionService\n",
    "from domain.services.blob_storage_service import BlobStorageService\n",
    "from domain.services.test_case_service import TestCaseService\n",
    "\n",
    "test_case_serv: TestCaseService = TestCaseServiceMongoDB(db_name)\n",
    "execution_serv: TestCaseExecutionService = TestCaseExecutionServiceMongoDB(db_name)\n",
    "\n",
    "blob_service: BlobStorageService = GoogleDriveBlobStorageService()\n",
    "model_storage: ModelStorageService = ModelStorageServiceGoogleDrive(blob_service)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Buscar caso de teste para executar e modelo salvo previamente"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from domain.models.test_case import TestCaseState\n",
    "\n",
    "last_test_case = test_case_serv.get_first_available()\n",
    "\n",
    "# Se não tiver nenhum caso disponível, finalize a execução\n",
    "if last_test_case is None:\n",
    "    print('Todos casos de teste finalizados!')\n",
    "    exit(0)\n",
    "    raise InterruptedError()\n",
    "\n",
    "test_case_serv.update_state(last_test_case['id'], TestCaseState.Busy)\n",
    "\n",
    "# Buscar última execução do caso de teste\n",
    "last_execution = execution_serv.get_last_execution(last_test_case['id'])\n",
    "\n",
    "model_id = None\n",
    "\n",
    "# Buscar último blob do modelo atualizado\n",
    "if last_execution:\n",
    "    model_id = last_execution['model_id']\n",
    "\n",
    "    if model_id:\n",
    "        model_storage.recover(model_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------CASO DE TESTE----------\n",
      "ID:             634af43680f1091a3fc55517\n",
      "Network:        Networks.UNet\n",
      "Backbone:       KerasBackbone.ResNet101\n",
      "Otimizador:     Optimizers.Adam\n",
      "Pesos imagenet: True\n",
      "---------------------------------\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from infra.util.output import print_test_case\n",
    "\n",
    "print_test_case(last_test_case)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baixar dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "if not os.path.exists('data'):\n",
    "    !git clone \"https://gitlab.com/siddinc/new_depth.git\" \"./data\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Particionar (em treino e teste) e instanciar geradores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from domain.models.data.data_generator import NyuV2Generator\n",
    "from infra.util.dataset import load_nyu_train_paths\n",
    "\n",
    "train_path = \"./data/nyu2_train.csv\"\n",
    "test_path = \"./data/nyu2_test.csv\"\n",
    "batch_size = 2\n",
    "\n",
    "# Defina a semente usada em operações como embaralhamento do dataset\n",
    "seed = 42\n",
    "\n",
    "partition = load_nyu_train_paths(train_path, val_percent=0.3, seed=seed, dataset_usage_percent=1)\n",
    "\n",
    "training_generator = NyuV2Generator(partition['train'], batch_size, shuffle=True, seed=seed)\n",
    "validation_generator = NyuV2Generator(partition['validation'], batch_size, shuffle=True, seed=seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparar modelo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definir configuração"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "input_shape = (image_size, image_size, 3)\n",
    "width, height, n_channels = input_shape\n",
    "max_epochs = 20\n",
    "initial_lr = 0.0001\n",
    "\n",
    "last_epoch = last_execution['last_epoch'] + 1 if last_execution else 0\n",
    "epochs = max_epochs - last_epoch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definir callbacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "network = last_test_case['network'].value\n",
    "optimizer = str(last_test_case['optimizer'].value).lower()\n",
    "backbone = str(last_test_case['backbone'].value).lower()\n",
    "use_image_net = int(last_test_case['use_imagenet_weights'])\n",
    "epoch = last_execution['last_epoch'] + 1 if last_execution else 1\n",
    "\n",
    "# Exemplo de formato: 'attention-unet_epoch-15_adam_resnet-101_imagenet-0'\n",
    "trained_model_name = f'{network}_{optimizer}_{backbone}_imagenet-{use_image_net}'\n",
    "csv_log_name = f'{trained_model_name}.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from infra.keras.metrics import build_poly_decay\n",
    "from infra.keras.callbacks import CSVResultsSave, TrainedModelSaveRemote\n",
    "from datetime import datetime\n",
    "from tensorflow.python.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, CSVLogger, ModelCheckpoint\n",
    "\n",
    "tensorboard_log_path = \"logs/fit/\"\n",
    "tensorboard_current_log_path = tensorboard_log_path + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=trained_model_name,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")\n",
    "save_model_remote_callback = TrainedModelSaveRemote(\n",
    "    model_storage,\n",
    "    execution_serv,\n",
    "    test_case_serv,\n",
    "    trained_model_name,\n",
    "    last_test_case['id'],\n",
    "    epoch\n",
    ")\n",
    "\n",
    "poly_decay = build_poly_decay(epochs, initial_lr)\n",
    "callbacks = [\n",
    "    LearningRateScheduler(poly_decay),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True),\n",
    "    CSVLogger(csv_log_name),\n",
    "    CSVResultsSave(blob_service, csv_log_name, epoch),\n",
    "    model_checkpoint_callback,\n",
    "    save_model_remote_callback,\n",
    "    TensorBoard(log_dir=tensorboard_current_log_path, histogram_freq=1),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compilar e treinar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171446536/171446536 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from infra.keras.model import build_model\n",
    "from infra.keras.loss import depth_loss\n",
    "from tensorflow import keras\n",
    "\n",
    "import infra.keras.metrics as tf_metrics\n",
    "\n",
    "if model_id is not None and last_execution is not None:\n",
    "    custom_objects = {\n",
    "        'poly_decay': poly_decay,\n",
    "        'depth_loss': depth_loss,\n",
    "        'abs_rel': tf_metrics.abs_rel,\n",
    "        'sq_rel': tf_metrics.sq_rel,\n",
    "        'rmse': tf_metrics.rmse,\n",
    "        'rmse_log': tf_metrics.rmse_log,\n",
    "        'log_10': tf_metrics.log_10,\n",
    "        'threshold_1': tf_metrics.threshold_1,\n",
    "        'threshold_2': tf_metrics.threshold_2,\n",
    "        'threshold_3': tf_metrics.threshold_3,\n",
    "    }\n",
    "    unet_model = keras.models.load_model(last_execution['model_name'], custom_objects)\n",
    "\n",
    "else:\n",
    "    unet_model = build_model(last_test_case, input_shape)\n",
    "\n",
    "metrics = [\n",
    "    tf_metrics.abs_rel,\n",
    "    tf_metrics.sq_rel,\n",
    "    tf_metrics.rmse,\n",
    "    tf_metrics.rmse_log,\n",
    "    tf_metrics.log_10,\n",
    "    tf_metrics.threshold_1,\n",
    "    tf_metrics.threshold_2,\n",
    "    tf_metrics.threshold_3,\n",
    "]\n",
    "unet_model.compile(loss=depth_loss, metrics=metrics, optimizer=optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n"
     ]
    }
   ],
   "source": [
    "unet_model.fit(training_generator, validation_data=validation_generator, callbacks=callbacks, epochs=epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "% load_ext tensorboard\n",
    "% tensorboard --logdir $tensorboard_log_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Avaliar na base de teste"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from infra.util.dataset import read_nyu_csv\n",
    "\n",
    "test_path_pairs = read_nyu_csv(test_path)\n",
    "test_generator = NyuV2Generator(test_path_pairs, batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from infra.keras.stages import evaluate\n",
    "\n",
    "evaluate(unet_model, test_generator, blob_service, csv_log_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exibir comparação entre predição e ground truth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from infra.util.output import plot_image_comparison\n",
    "import random\n",
    "\n",
    "n_plot = 10\n",
    "\n",
    "xy_pairs = test_path_pairs.copy()\n",
    "random.seed(seed)\n",
    "random.shuffle(xy_pairs)\n",
    "xy_pairs = xy_pairs[:n_plot]\n",
    "\n",
    "plot_image_comparison(unet_model, xy_pairs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finalizar caso de teste\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_case_serv.update_state(last_test_case['id'], TestCaseState.Done)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
