{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# U-Net Depth (Projeto de dissertação)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clonar e navegar para o repositório"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clone o repositório da dissertação\n",
    "!git clone \"https://github.com/duraes-antonio/unet_depth\"\n",
    "\n",
    "# Navegue para o repositório\n",
    "!cd \"unet_depth\"\n",
    "os.chdir(\"unet_depth\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definir variáveis de ambiente e credenciais para serviços"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "running_remote = True\n",
    "running_on_kaggle = True\n",
    "db_name = 'unet_depth'\n",
    "\n",
    "if running_remote:\n",
    "    !pip install pymongo[srv] dnspython keras-unet-collection python-dotenv imutils\n",
    "    !pip install py-cpuinfo gpuinfo\n",
    "\n",
    "if running_on_kaggle:\n",
    "    user_secrets = UserSecretsClient()\n",
    "    database_url = user_secrets.get_secret(\"DATABASE_URL\")\n",
    "    google_cred_json = ast.literal_eval(user_secrets.get_secret(\"GOOGLE_CREDENTIALS_JSON\"))\n",
    "    google_token_json = ast.literal_eval(user_secrets.get_secret(\"GOOGLE_TOKEN_JSON\"))\n",
    "\n",
    "    with open('google_credentials.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(google_cred_json, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    with open('token.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(google_token_json, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    os.environ[\"DATABASE_URL\"] = database_url\n",
    "    os.environ[\"DB_NAME\"] = db_name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instanciar serviços para persistência de resultados e blob"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from infra.services.blob_storage.blob_storage_service_google_drive import GoogleDriveBlobStorageService\n",
    "from infra.services.model_storage_service_google_drive import ModelStorageServiceGoogleDrive\n",
    "from domain.services.model_storage_service import ModelStorageService\n",
    "from infra.services.test_case_execution_service_mongodb import TestCaseExecutionServiceMongoDB\n",
    "from infra.services.test_case_service_mongodb import TestCaseServiceMongoDB\n",
    "from domain.services.test_case_execution_service import TestCaseExecutionService\n",
    "from domain.services.blob_storage_service import BlobStorageService\n",
    "from domain.services.test_case_service import TestCaseService\n",
    "\n",
    "test_case_serv: TestCaseService = TestCaseServiceMongoDB(db_name)\n",
    "execution_serv: TestCaseExecutionService = TestCaseExecutionServiceMongoDB(db_name)\n",
    "\n",
    "blob_service: BlobStorageService = GoogleDriveBlobStorageService()\n",
    "model_storage: ModelStorageService = ModelStorageServiceGoogleDrive(blob_service)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Buscar caso de teste para executar e modelo salvo previamente"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from domain.models.test_case import TestCaseState\n",
    "\n",
    "last_test_case = test_case_serv.get_first_available()\n",
    "\n",
    "# Se não tiver nenhum caso disponível, finalize a execução\n",
    "if last_test_case is None:\n",
    "    print('Todos casos de teste finalizados!')\n",
    "    exit(0)\n",
    "    raise InterruptedError()\n",
    "\n",
    "test_case_serv.update_state(last_test_case['id'], TestCaseState.Busy)\n",
    "\n",
    "# Buscar última execução do caso de teste\n",
    "last_execution = execution_serv.get_last_execution(last_test_case['id'])\n",
    "\n",
    "model_id = None\n",
    "\n",
    "# Buscar último blob do modelo atualizado\n",
    "if last_execution:\n",
    "    model_id = last_execution['model_id']\n",
    "\n",
    "    if model_id:\n",
    "        model_storage.recover(model_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from infra.util.output import print_test_case\n",
    "\n",
    "print_test_case(last_test_case)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baixar dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone \"https://gitlab.com/siddinc/new_depth.git\" \"./data\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Particionar (em treino e teste) e instanciar geradores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from domain.models.data.data_generator import NyuV2Generator\n",
    "from infra.util.dataset import load_nyu_train_paths\n",
    "\n",
    "train_path = \"./data/nyu2_train.csv\"\n",
    "test_path = \"./data/nyu2_test.csv\"\n",
    "batch_size = 4\n",
    "\n",
    "# Defina a semente usada em operações pseudo-aleatórias (como embaralhamento do dataset)\n",
    "seed = 42\n",
    "\n",
    "partition, y_path_by_x_path = load_nyu_train_paths(train_path, 0.3, seed, dataset_usage_percent=0.1)\n",
    "\n",
    "training_generator = NyuV2Generator(partition['train'], y_path_by_x_path, batch_size, seed=seed)\n",
    "validation_generator = NyuV2Generator(partition['validation'], y_path_by_x_path, batch_size, seed=seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparar modelo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definir configuração"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "input_shape = (image_size, image_size, 3)\n",
    "width, height, n_channels = input_shape\n",
    "epochs = 50\n",
    "initial_lr = 0.0001"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definir callbacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = last_test_case['network'].value\n",
    "optimizer: str = last_test_case['optimizer'].value\n",
    "backbone = str(last_test_case['backbone'].value).lower()\n",
    "use_image_net = int(last_test_case['use_imagenet_weights'])\n",
    "epoch = last_execution['last_epoch'] + 1 if last_execution else 1\n",
    "\n",
    "# Exemplo de formato: 'attention-unet_epoch-15_adam_resnet-101_imagenet-0'\n",
    "trained_model_name = f'{network}_{optimizer}_{backbone}_imagenet-{use_image_net}'\n",
    "csv_log_name = f'{trained_model_name}.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from infra.keras.metrics import build_poly_decay\n",
    "from infra.keras.callbacks import CSVResultsSave, TrainedModelSaveRemote\n",
    "from datetime import datetime\n",
    "from tensorflow.python.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, CSVLogger, ModelCheckpoint\n",
    "\n",
    "tensorboard_log_path = \"logs/fit/\"\n",
    "tensorboard_current_log_path = tensorboard_log_path + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=trained_model_name,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")\n",
    "save_model_remote_callback = TrainedModelSaveRemote(\n",
    "    model_storage,\n",
    "    execution_serv,\n",
    "    test_case_serv,\n",
    "    trained_model_name,\n",
    "    last_test_case['id'],\n",
    "    epoch\n",
    ")\n",
    "\n",
    "poly_decay = build_poly_decay(epochs, initial_lr)\n",
    "callbacks = [\n",
    "    LearningRateScheduler(poly_decay),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True),\n",
    "    CSVLogger(csv_log_name),\n",
    "    CSVResultsSave(blob_service, csv_log_name, epoch),\n",
    "    model_checkpoint_callback,\n",
    "    save_model_remote_callback,\n",
    "    TensorBoard(log_dir=tensorboard_current_log_path, histogram_freq=1),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compilar e treinar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from infra.keras.model import build_model\n",
    "from infra.keras.loss import depth_loss\n",
    "from infra.keras.metrics import depth_acc\n",
    "from tensorflow import keras\n",
    "\n",
    "if model_id is not None and last_execution is not None:\n",
    "    custom_objects = {'poly_decay': poly_decay, 'depth_loss': depth_loss, 'depth_acc': depth_acc}\n",
    "    unet_model = keras.models.load_model(last_execution['model_name'], custom_objects)\n",
    "\n",
    "else:\n",
    "    unet_model = build_model(last_test_case, input_shape)\n",
    "\n",
    "unet_model.compile(loss=depth_loss, metrics=[depth_acc], optimizer=optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unet_model.fit(training_generator, validation_data=validation_generator, callbacks=callbacks, epochs=epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "% load_ext tensorboard\n",
    "% tensorboard --logdir $tensorboard_log_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Avaliar na base de teste"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from infra.util.dataset import read_nyu_csv\n",
    "\n",
    "img_path_pairs = read_nyu_csv(test_path)\n",
    "labels = {x_path: y_path for x_path, y_path in img_path_pairs}\n",
    "labels_path = [y_path for x_path, y_path in img_path_pairs]\n",
    "\n",
    "test_paths = [x_path for x_path, y_path in img_path_pairs]\n",
    "partition = {'test': test_paths}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from infra.util.preprocessing import preprocess_image\n",
    "from infra.util.preprocessing import preprocess_depth_map\n",
    "import numpy\n",
    "\n",
    "x_test = numpy.empty((len(test_paths), height, width, n_channels))\n",
    "y_test = numpy.empty((len(test_paths), height, width, 1))\n",
    "\n",
    "for index, ID in enumerate(partition['test'][:]):\n",
    "    x_test[index,] = preprocess_image(ID)\n",
    "    y_test[index,] = preprocess_depth_map(labels[ID])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unet_model.evaluate(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exibir comparação entre predição e ground truth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from infra.util.output import plot_image_comparison\n",
    "\n",
    "plot_image_comparison(unet_model, x_test, labels_path, 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
